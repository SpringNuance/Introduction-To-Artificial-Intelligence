{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Generative Autoencoder Model\n",
    "**Generative models** are able to learn to represent a certain distribution of data, such as images, and then generate novel random samples indistinguishable from the original examples. Currently, the most common generative models are Generative Adversarial Networks (GAN).\n",
    "\n",
    "On the other hand, **autoencoder models** can learn to encode new images into a low-dimensional (compressed) representation, which we refer to as the latent (or unobserved) code. This representation can be used to manipulate the images in semantically meaningful ways, such as changing the shape of the nose or rotating the azimuth of the face.\n",
    "\n",
    "Recently, Balanced PIONEER networks (Progressively Growing Generative Autoencoders) [1] were introduced to combine the best of both worlds. They can both encode new input images for image editing purposes and generate completely novel random images.\n",
    "\n",
    "For this exercise, we will be using a pre-trained PIONEER model on images with 256x256 resolution, trained with the CelebA-HQ dataset which contains 30,000 images of celebrities, using the codebase [2].\n",
    "\n",
    "[1] Heljakka, A., Solin, A., and Kannala, J. Towards Photographic Image Manipulation with Balanced Growing of Generative Autoencoders. In Winter Conference on Applications of Computer Vision (WACV), 2020.\n",
    "\n",
    "[2] https://github.com/AaltoVision/balanced-pioneer\n",
    "\n",
    "## Task 1: Load the model\n",
    "\n",
    "Take a moment to make sure you are familiar with the concepts of autoencoders, generative models, and the use of a pre-trained machine learning model. Then run the following code as-is.\n",
    "\n",
    "In Jupyter, the model works slower than it should. Please take a moment to consider the reason:\n",
    "In regular neural networks and deep learning setup, we would use a GPU to load and run the model. It would load and operate up 10-100x faster. In this environment, we use the CPU. Make sure you understand, on a high level, why GPU is so much faster for these tasks. You can Google the answer. For your own work, you can use any GPU in principle, e.g. gaming PCs. NVIDIA GPUs tend to have the best compatibility at the moment.\n",
    "\n",
    "**To run a cell of code, click inside the cell, and then click Run in the menu bar**.\n",
    "\n",
    "If you run out of memory or encounter \"data errors\" or similar during the running of this exercise, please restart the kernel (select **Kernel / Restart** in the menu bar), re-run cells 1-3, and then continue from the cell that you were working with!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up - Utility Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.argv = ['no']\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pioneer import utils\n",
    "from pioneer import config\n",
    "from pioneer import train\n",
    "from pioneer import data\n",
    "from pioneer import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_session_setup(dataset_name, model_path, test_images_path, reso, load_checkpoint = -1):\n",
    "    \"\"\"load_checkpoint = The checkpoint to start from. -1 = load the newest. 0 = start from scratch.\n",
    "    \"\"\"\n",
    "    global args\n",
    "    args = config.get_config()\n",
    "    args.data = dataset_name\n",
    "    args.save_dir = model_path\n",
    "    args.start_iteration = load_checkpoint\n",
    "    args.test_path = test_images_path\n",
    "    args.testonly = True\n",
    "    args.disable_cuda = True\n",
    "    args.max_phase = int(np.log2(reso/4))\n",
    "    args.e_last_relu = True\n",
    "    args.upsampling = 'bilinear0' #Smoothen the last layer\n",
    "    args.no_TB = True\n",
    "    \n",
    "    train.setup()\n",
    "        \n",
    "    session = train.Session()\n",
    "    session.create()\n",
    "    test_data_loader = data.get_loader(args.data, args.test_path)\n",
    "    \n",
    "    #evaluate.Utils.reconstruction_dryrun(session.g_running, session.encoder, test_data_loader, session=session)\n",
    "    \n",
    "    return session, test_data_loader\n",
    "\n",
    "def get_data_iterator(session, loader, nr_of_images = 8, resolution = 64):\n",
    "    return data.Utils.sample_data2(loader, min(nr_of_images, 16), resolution, session)\n",
    "\n",
    "def encode(session, img):\n",
    "    return session.encoder(img, session.phase, 1.0, False)\n",
    "\n",
    "def decode(session, z):\n",
    "    return session.generator(z, None, session.phase, 1.0)\n",
    "\n",
    "def decode_running(session, z):\n",
    "    return session.g_running(z, None, session.phase, 1.0)\n",
    "\n",
    "%matplotlib inline\n",
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    fig = plt.figure(figsize=(15,27))\n",
    "    plt.imshow(np.transpose(npimg / max(npimg.max(), -npimg.min()), (1,2,0)) / 2 + 0.5, interpolation='nearest')\n",
    "    \n",
    "def show_grid(imgs1):\n",
    "    grid = (make_grid(imgs1[:], padding=5, nrow=5))\n",
    "    show(grid)\n",
    "\n",
    "def show_pairs(imgs1, imgs2):\n",
    "    t = torch.FloatTensor(imgs1.size(0) * 2, imgs1.size(1),\n",
    "                          imgs1.size(2), imgs1.size(3))\n",
    "\n",
    "    t[0::2] = imgs1[:]\n",
    "    t[1::2] = imgs2[:]\n",
    "\n",
    "    grid = (make_grid(t[:imgs1.size(0)*2] , padding=5, nrow=2)) #/ 2 + 0.5\n",
    "\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    show(grid)\n",
    "    \n",
    "    return grid\n",
    "\n",
    "def show_triple(imgs1, imgs2, imgs3):\n",
    "    t = torch.FloatTensor(imgs1.size(0) * 3, imgs1.size(1),\n",
    "                          imgs1.size(2), imgs1.size(3))\n",
    "\n",
    "    t[0::3] = imgs1[:]\n",
    "    t[1::3] = imgs2[:]\n",
    "    t[2::3] = imgs3[:]\n",
    "\n",
    "    grid = (make_grid(t[:imgs1.size(0)*3] , padding=5, nrow=3))\n",
    "\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    show(grid)\n",
    "    \n",
    "    return grid\n",
    "\n",
    "def show_5(imgs1, imgs2, imgs3, imgs4, imgs5):\n",
    "    t = torch.FloatTensor(imgs1.size(0) * 5, imgs1.size(1),\n",
    "                          imgs1.size(2), imgs1.size(3))\n",
    "\n",
    "    t[0::5] = imgs1[:]\n",
    "    t[1::5] = imgs2[:]\n",
    "    t[2::5] = imgs3[:]\n",
    "    t[3::5] = imgs4[:]\n",
    "    t[4::5] = imgs5[:]\n",
    "\n",
    "    grid = (make_grid(t[:imgs1.size(0)*5] , padding=5, nrow=5))\n",
    "\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    show(grid)\n",
    "    \n",
    "    return grid\n",
    "\n",
    "def reconstruct(session, data_iterator):\n",
    "    source_images, _ = next(data_iterator)\n",
    "    with torch.no_grad():\n",
    "        z = encode(session, source_images)\n",
    "        dest_images = decode_running(session, z)\n",
    "        show_pairs(source_images, dest_images)\n",
    "        \n",
    "def random_faces(session, random_id, num_imgs):\n",
    "    import random\n",
    "    random.seed(random_id)\n",
    "    torch.manual_seed(random_id)\n",
    "    torch.cuda.manual_seed_all(random_id)   \n",
    "    \n",
    "    from torch.autograd import Variable\n",
    "    with torch.no_grad():\n",
    "        myz = Variable(torch.randn(num_imgs, 512))#.cuda()\n",
    "        myz = utils.normalize(myz)\n",
    "        myz, input_class = utils.split_labels_out_of_latent(myz)\n",
    "    \n",
    "        new_imgs = session.g_running(\n",
    "            myz,\n",
    "            input_class,\n",
    "            session.phase,\n",
    "            1.0).detach().data.cpu()\n",
    "    return new_imgs\n",
    "\n",
    "def show_feat(session, it, feat_delta, alphas = [0.33, 0.66, 1.0]):\n",
    "    mo_source_images, _ = next(it)\n",
    "    with torch.no_grad():\n",
    "        z = encode(session, mo_source_images)\n",
    "        mo_dest_images = decode_running(session, z)\n",
    "        z2 = z + alphas[0] * feat_delta\n",
    "        force_feat_images1 = decode_running(session, z2)\n",
    "        z3 = z + alphas[1] * feat_delta\n",
    "        force_feat_images2 = decode_running(session, z3)\n",
    "        z4 = z + alphas[2] * feat_delta\n",
    "        force_feat_images3 = decode_running(session, z4)\n",
    "        show_5(mo_source_images, mo_dest_images, force_feat_images1, force_feat_images2, force_feat_images3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pre-trained Pioneer model\n",
    "\n",
    "This may take a few moments - wait for the star [*] to disappear on the left of the cell before continuing.\n",
    "\n",
    "Note: You may see some deprecation warnings when running the below code. They are harmless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session, test_data_loader = test_session_setup(\n",
    "            dataset_name = 'celebaHQ',\n",
    "            model_path = '/coursedata/celebaHQ256',\n",
    "            test_images_path = 'pioneer/test_256_in',\n",
    "            reso = 256,\n",
    "            load_checkpoint = 25480000\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Generate random faces from the model with your student ID\n",
    "\n",
    "A proper generative model can generate a completely fabricated sample based on a random (noise) input.\n",
    "In this case, your student ID can serve as the *random seed* for the noise input. The input itself is a 512-dimensional random vector.\n",
    "Often these vectors are generated from the Gaussian (aka \"normal\") distribution, due to their nice theoretical properties. Try generating some random faces below. Note: The images are 128x128, so if they look pixelated, please pay attention to your screen resolution, since your browser may stretch them.\n",
    "\n",
    "Sometimes, the images will look so realistic that you might think the model is cheating somehow. We will soon show a way to ensure that this is not the case. Sometimes, though, the images will be completely broken in various but often interesting ways. You can experiment with replacing the student_id with any integer and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_id = 123456789 # <= Insert your student ID here (numbers only)\n",
    "imgs = random_faces(session, student_id, 4)\n",
    "show_grid(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Reconstruct a face image\n",
    "Autoencoders have the capability to encode an input sample (here, a face) into a very compact internal representation called a 'latent code'.\n",
    "This is similar to compressing an image very tightly.\n",
    "The latent code can then be decoded back into an image, which we would like to resemble the original image as much as possible.\n",
    "Take a moment to consider why we do this. What would be the benefit of having the latent code? What could we do with it?\n",
    "Below, you load in some images from the test dataset and ask the model to encode them into latent space, and then decode back to the image space.\n",
    "The images on the left are originals and the ones on the right are reconstructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = get_data_iterator(session, test_data_loader, 1, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct(session,it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Interpolate between two faces\n",
    "Consider taking two images as input. The autoencoder creates a latent code for both. Now, these codes are just 512-dimensional vectors (sequences of numbers). What happens if we change them slightly? What happens if we take the vector that is exactly between them?\n",
    "Try it out below! First, we encode the images into the latent code 'z'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = get_data_iterator(session, test_data_loader, 2, 256)\n",
    "\n",
    "source_images, _ = next(it)\n",
    "with torch.no_grad():\n",
    "    z = encode(session, source_images)\n",
    "np.shape(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we take the latent codes of the two reconstructed images, and find out the vector that is exactly in the middle of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mid = (torch.FloatTensor(3, z[0].size(0)))\n",
    "\n",
    "z_mid[0] = z[0]\n",
    "z_mid[2] = z[1]\n",
    "z_mid[1] = z[0] + (z[1] - z[0])/2\n",
    "\n",
    "# To conserve memory in Jupyter, we will decode images 1-by-1. Normally we would do them in a single batch.\n",
    "imgs = (torch.FloatTensor(3, 3,256,256))\n",
    "\n",
    "for i in range(3):\n",
    "    with torch.no_grad():\n",
    "        imgs[i,:,:,:] = decode_running(session, z_mid[i].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs2 = (torch.FloatTensor(5, 3,256,256))\n",
    "imgs2[1:4,:,:,:] = imgs\n",
    "imgs2[0,:,:,:] = source_images[0]\n",
    "imgs2[4,:,:,:] = source_images[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_grid(imgs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hold on. Why do we need to do this? We could just take the average between the pixels of the two images, right?\n",
    "Yes, we can. We try this below. But depending on which samples you see, it often fails. Can you explain why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs3 = (torch.FloatTensor(3, 3,256,256))\n",
    "imgs3[0,:,:,:] = source_images[0]\n",
    "imgs3[1,:,:,:] = (source_images[0] + source_images[1]) / 2\n",
    "imgs3[2,:,:,:] = source_images[1]\n",
    "show_grid(imgs3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Modify specific image attributes in latent space\n",
    "We can do much more by latent representation manipulation.\n",
    "For instance, if we have found the direction in the latent space that corresponds to smiling, we can make a new person smile by adding the smile vector to his/her latent code. Let's try it out!\n",
    "\n",
    "If you get an error \"DataLoader worker ... is killed by signal: Killed.\" or similar errors, please do the following:\n",
    "1. Select Kernel / Restart in the menu bar\n",
    "2. Re-run only cells 1-3\n",
    "3. Continue directly from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smile_delta = torch.load('pioneer/attrib/smile_delta',  map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = get_data_iterator(session, test_data_loader, 1, 256)\n",
    "\n",
    "show_feat(session, it, smile_delta, alphas = [0.33, 0.66, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different values of alpha modify the smile vector. That is, if alpha=0, then the smile will not change.\n",
    "Find the best alpha values for some input image.\n",
    "What happens if you use negative values of alpha? For what purpose could you use the negative values?\n",
    "\n",
    "How would you create the smile_delta vector? It is easier than one might think!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL Task 6\n",
    "\n",
    "**These optional tasks are for students already familiar with coding in Python, and are not graded.**\n",
    "\n",
    "Now you may have an idea of why the latent codes are so useful. We can modify images on a more abstract level by modifying the code. But instead of just taking the middle point between two faces, we can actually take any points between them, and decode them back to image space, as long as they are strictly along the vector that connects the two codes.\n",
    "\n",
    "In task #4 we just took the middle point between the two vectors.\n",
    "Try writing the code that produces 5 intermediate points between the two vectors, with evenly spaced intervals (e.g. in 1-dimension, if your latent codes are 2 and 5, you would generate the intermediate points 2.5, 3.0, 3.5, 4, and 4.5).\n",
    "Then, decode these back to the image space.\n",
    "You should see a smooth transition from one image to the next.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIONAL Task 7\n",
    "Find your own face images at 128x128 resolution and align the images as exactly as possible to resemble the test images given here. (The resolution must be exact and their eye positions must align as well as possible.)\n",
    "Upload the aligned images to the Jupyter environment.\n",
    "Run the reconstructions and interpolations for your own images.\n",
    "Does the reconstruction look good? If not, consider why this could be the case. Note that the model has been trained with a dataset that has many more female than male faces, so it often reconstructs male faces as female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
